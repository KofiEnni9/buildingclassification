{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gTvtwcyfYrpU"
   },
   "outputs": [],
   "source": [
    "!pip -q install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqLnePK678QT",
    "outputId": "c31be523-b564-41e8-a6e9-92fbedcbb5ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.3/838.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m892.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "eqBnZMFvYyYI",
    "outputId": "58803ae6-fc26-4b37-e7a6-d11a6c32fb4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "S8EKbIh3Gcgc"
   },
   "outputs": [],
   "source": [
    "data_dir = '/content/thedataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dsZlloufsxXg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Path to the directory where your images are stored\n",
    "image_dir = '/content/drive/MyDrive/CampusVisionChallengeFinal.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnDEiGCKAOFO"
   },
   "source": [
    "# FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhhCP7aSAa92",
    "outputId": "865a7e71-b8fb-4c83-ebda-e33294b8dcd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset unzipped to /content/thedataset/\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Path to your .zip file (adjust if it's stored in Google Drive or a different location)\n",
    "zip_file_path = '/content/drive/MyDrive/CampusVisionChallengeFinal.zip'\n",
    "unzip_dir = '/content/thedataset/'  # Directory where the images will be extracted\n",
    "\n",
    "# Step 1: Unzipping the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_dir)\n",
    "    print(f\"Dataset unzipped to {unzip_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIozRwkG67eK",
    "outputId": "52b26fcf-73d0-4a95-ff11-d648c676110c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed splitting for folder: Simrall Hall\n",
      "Completed splitting for folder: Walker Hall\n",
      "Completed splitting for folder: Lee Hall\n",
      "Completed splitting for folder: Old Main\n",
      "Completed splitting for folder: Carpenter Hall\n",
      "Completed splitting for folder: Butler Hall\n",
      "Completed splitting for folder: Swalm Hall\n",
      "Completed splitting for folder: McCool Hall\n",
      "Completed splitting for folder: McCain Hall\n",
      "Completed splitting for folder: Student Union\n",
      "Dataset split completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "dataset_dir = '/content/thedataset/MergeDataset'  # Path to the main dataset folder\n",
    "output_dir = '/content/thedataset/'  # Path to save the train/val splits\n",
    "\n",
    "# Split ratio\n",
    "val_split = 0.2  # 20% for validation\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for split in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(output_dir, split), exist_ok=True)\n",
    "\n",
    "# Iterate over the 10 class folders\n",
    "for folder_name in os.listdir(dataset_dir):\n",
    "    folder_path = os.path.join(dataset_dir, folder_name)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Create train and val directories for each class folder\n",
    "        for split in ['train', 'val']:\n",
    "            os.makedirs(os.path.join(output_dir, split, folder_name), exist_ok=True)\n",
    "\n",
    "        # List all image files in the folder\n",
    "        images = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "        # Split the dataset into train and val\n",
    "        train_images, val_images = train_test_split(images, test_size=val_split, random_state=42)\n",
    "\n",
    "        # Copy the images to the respective directories\n",
    "        for img in train_images:\n",
    "            shutil.copy(os.path.join(folder_path, img), os.path.join(output_dir, 'train', folder_name, img))\n",
    "        for img in val_images:\n",
    "            shutil.copy(os.path.join(folder_path, img), os.path.join(output_dir, 'val', folder_name, img))\n",
    "\n",
    "        print(f\"Completed splitting for folder: {folder_name}\")\n",
    "\n",
    "print(\"Dataset split completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZDM3LT3l2oO"
   },
   "source": [
    "# working well. Using resnet34.without no tunning. hope to ward to do better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "H9Y9cpsUHMr2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, log_loss\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gRGIanmWHQ9C"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "d159GoI6w7m8"
   },
   "outputs": [],
   "source": [
    "class GaussianBlur(object):\n",
    "    \"\"\"Apply Gaussian blur with random sigma\"\"\"\n",
    "    def __init__(self, radius_min=0.1, radius_max=2.0):\n",
    "        self.radius_min = radius_min\n",
    "        self.radius_max = radius_max\n",
    "\n",
    "    def __call__(self, img):\n",
    "        radius = random.uniform(self.radius_min, self.radius_max)\n",
    "        return img.filter(ImageFilter.GaussianBlur(radius=radius))\n",
    "\n",
    "def get_data_transforms():\n",
    "    \"\"\"\n",
    "    Define data transformations for training and validation.\n",
    "    Ensures consistent image sizes throughout the pipeline.\n",
    "    \"\"\"\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            # First resize to a slightly larger size\n",
    "            transforms.Resize(580),\n",
    "            # Then always crop to target size\n",
    "            transforms.RandomCrop(512),\n",
    "\n",
    "            # Color augmentations\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.2,\n",
    "                contrast=0.2,\n",
    "                saturation=0.2,\n",
    "                hue=0.1\n",
    "            ),\n",
    "\n",
    "            # Geometric transformations\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.2),\n",
    "            transforms.RandomApply([\n",
    "                transforms.RandomRotation(10)\n",
    "            ], p=0.3),\n",
    "\n",
    "            # Weather and lighting simulations\n",
    "            transforms.RandomApply([GaussianBlur(0.1, 2.0)], p=0.2),\n",
    "\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "\n",
    "            # Random erasing (after normalization)\n",
    "            transforms.RandomErasing(\n",
    "                p=0.2,\n",
    "                scale=(0.02, 0.1),\n",
    "                ratio=(0.3, 3.3),\n",
    "                value='random'\n",
    "            )\n",
    "        ]),\n",
    "\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(580),\n",
    "            transforms.CenterCrop(512),  # Consistent crop size\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "    }\n",
    "    return data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Altz9HJlMDVA"
   },
   "outputs": [],
   "source": [
    "class RobustImageFolder(datasets.ImageFolder):\n",
    "    \"\"\"Custom ImageFolder that handles corrupt images\"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            return super().__getitem__(index)\n",
    "        except (OSError, IOError) as e:\n",
    "            print(f\"Warning: Skipping corrupt image at index {index}\")\n",
    "            valid_idx = (index + 1) % len(self)\n",
    "            return super().__getitem__(valid_idx)\n",
    "\n",
    "def load_data(data_dir, batch_size=32):\n",
    "    \"\"\"\n",
    "    Load and prepare data loaders\n",
    "    Reduced batch size and number of workers for better stability\n",
    "    \"\"\"\n",
    "    data_transforms = get_data_transforms()\n",
    "    image_datasets = {x: RobustImageFolder(os.path.join(data_dir, x),\n",
    "                                         data_transforms[x])\n",
    "                     for x in ['train', 'val']}\n",
    "\n",
    "    dataloaders = {x: DataLoader(image_datasets[x],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=2,  # Reduced number of workers\n",
    "                                pin_memory=True)  # Added pin_memory for better performance\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    class_names = image_datasets['train'].classes\n",
    "    return dataloaders, dataset_sizes, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "id": "CMYFkAA5xAs_"
   },
   "outputs": [],
   "source": [
    "# Step 3: Define the Model\n",
    "# ------------------------\n",
    "def create_model(num_classes):\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    # Get the input dimensions of the last layer (fully connected layer)\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    # Replace the last layer with a new one that has `num_classes` outputs\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qPHKgAJGxAxE"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Train the Model\n",
    "# -----------------------\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n",
    "    best_model_wts = model.state_dict()  # Store the best model weights\n",
    "    best_acc = 0.0  # Track the best validation accuracy\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set the model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set the model to evaluation mode\n",
    "\n",
    "            running_loss = 0.0  # Track the loss\n",
    "            running_corrects = 0  # Track the number of correct predictions\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)  # Move data to the GPU/CPU\n",
    "\n",
    "                optimizer.zero_grad()  # Clear the gradients\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)  # Forward pass\n",
    "                    _, preds = torch.max(outputs, 1)  # Get the class with the highest score\n",
    "                    loss = criterion(outputs, labels)  # Calculate the loss\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()  # Backpropagate the loss\n",
    "                        optimizer.step()  # Update the weights\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "                torch.save(model.state_dict(), \"best_model.pth\")\n",
    "                print(f\"Saved new best model\")\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DbgH11vOocTp"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Evaluate the Model\n",
    "# --------------------------\n",
    "def evaluate_model(model, dataloader, criterion, class_names):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Calculate the loss\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)  # Get the class with the highest score\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)  # Get probabilities\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())  # Store true labels\n",
    "            all_preds.extend(preds.cpu().numpy())    # Store predicted labels\n",
    "            all_probs.extend(probs.cpu().numpy())    # Store probabilities\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader.dataset)  # Calculate average loss\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "    logloss = log_loss(all_labels, all_probs)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Log Loss: {logloss:.4f}')\n",
    "\n",
    "    return accuracy, precision, recall, f1, logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uGG6e0GIocQW",
    "outputId": "df899cb7-d147-4301-8f80-aaa6411ac304"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 168MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.7336 Acc: 0.5850\n",
      "val Loss: 0.7313 Acc: 0.8879\n",
      "Saved new best model\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.5375 Acc: 0.8888\n",
      "val Loss: 0.2052 Acc: 0.9576\n",
      "Saved new best model\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.2300 Acc: 0.9517\n",
      "val Loss: 0.1039 Acc: 0.9778\n",
      "Saved new best model\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.1321 Acc: 0.9728\n",
      "val Loss: 0.0715 Acc: 0.9857\n",
      "Saved new best model\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.0934 Acc: 0.9807\n",
      "val Loss: 0.0551 Acc: 0.9893\n",
      "Saved new best model\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.0701 Acc: 0.9848\n",
      "val Loss: 0.0457 Acc: 0.9913\n",
      "Saved new best model\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.0597 Acc: 0.9875\n",
      "val Loss: 0.0400 Acc: 0.9925\n",
      "Saved new best model\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.0478 Acc: 0.9889\n",
      "val Loss: 0.0380 Acc: 0.9913\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.0407 Acc: 0.9908\n",
      "val Loss: 0.0326 Acc: 0.9937\n",
      "Saved new best model\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.0345 Acc: 0.9923\n",
      "val Loss: 0.0307 Acc: 0.9941\n",
      "Saved new best model\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.0327 Acc: 0.9927\n",
      "val Loss: 0.0304 Acc: 0.9945\n",
      "Saved new best model\n",
      "Epoch 11/19\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-adb12d226fb2>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-1196f52d36fe>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# Track the number of correct predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Move data to the GPU/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloaders, dataset_sizes, class_names = load_data(data_dir)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = create_model(num_classes=len(class_names))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, dataloaders, criterion, optimizer, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DwSK8ekH67bD",
    "outputId": "ea841e7b-3bf4-4067-a181-c11b1b076b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:2956: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9945\n",
      "Precision: 0.9945\n",
      "Recall: 0.9945\n",
      "F1 Score: 0.9945\n",
      "Log Loss: 0.0300\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "print(\"Validation Set Performance:\")\n",
    "evaluate_model(model, dataloaders['val'], criterion, class_names)\n",
    "\n",
    "# Save the best model\n",
    "torch.save(model.state_dict(), \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uN6Vns84X7L"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "def load_image(image_path):\n",
    "    # Open the image file\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return image\n",
    "\n",
    "# Define a transformation pipeline for resizing and normalization\n",
    "def preprocess_image(image, target_size=(256, 256)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(target_size),  # Resize to 256x256\n",
    "        transforms.ToTensor(),           # Convert to a PyTorch tensor\n",
    "        transforms.Normalize(mean=[0.4608, 0.4610, 0.4559], std=[0.2312, 0.2275, 0.2638])  # Normalize with same mean and std in which it was trained\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "# Perform inference with resizing and normalization\n",
    "def infer_with_resizing(model, image_path, class_names):\n",
    "    # Load and preprocess the image\n",
    "    image = load_image(image_path)\n",
    "    image = preprocess_image(image)\n",
    "\n",
    "    # Add a batch dimension (1, C, H, W)\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    # Move the input tensor to the same device as the model\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Make sure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    # Get the predicted class\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ltWyZ4Q2j7j3",
    "outputId": "cbcafdee-5079-44b8-9b2d-070510fe0fc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-493d6d341e1c>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Carpenter Hall\n"
     ]
    }
   ],
   "source": [
    "# Load the model and class names\n",
    "model = create_model(num_classes=len(class_names))\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Perform inference\n",
    "image_path = '/content/thedataset/val/Carpenter Hall/20241013_220952549_iOS.png'\n",
    "predicted_class = infer_with_resizing(model, image_path, class_names)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4glzDvZFB4D",
    "outputId": "0c5590bc-d17a-40f2-cab3-931c3679d618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Walker Hall\n"
     ]
    }
   ],
   "source": [
    "# Perform inference\n",
    "image_path = '/content/Screenshot (992).png'\n",
    "predicted_class = infer_with_resizing(model, image_path, class_names)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
